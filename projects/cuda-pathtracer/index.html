<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CUDA Pathtracer | Yuanqi Wang </title> <meta name="author" content="Yuanqi Wang"> <meta name="description" content="Monte Carlo pathTracer written in CUDA, C++"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.yqwong.com/projects/cuda-pathtracer/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yuanqi</span> Wang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">CUDA Pathtracer</h1> <p class="post-description">Monte Carlo pathTracer written in CUDA, C++</p> </header> <article> <p><a href="https://github.com/plasmas/Project3-CUDA-Path-Tracer" rel="external nofollow noopener" target="_blank">Source</a></p> <p><em>Tested on: Windows 11, i5-11600K @ 3.91GHz 32GB, RTX 4090 24GB (Personal Desktop)</em></p> <h1 id="overview">Overview</h1> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/showcase.png" style="width: 100%; height: auto;"> <p>Showcase Scene</p> </div> <p>A CUDA-based path tracer based on Monte Carlo sampling.</p> <p>This path tracer harnesses the parallel processing power of modern NVIDIA GPUs using CUDA to simulate the transport of light in a 3D scene. The Monte Carlo approach allows for accurate simulations of complex lighting phenomena, such as global illumination, caustics, and multiple reflections.</p> <hr> <h2 id="feature-list">Feature List</h2> <ul> <li> <p><strong>Optimized Performance</strong>: By leveraging the CUDA platform, the path tracer significantly boosts ray tracing speeds, distributing ray computations across numerous GPU cores. Additional optimizations include:</p> <ul> <li>Stream compaction and material sorting to minimize warp divergence.</li> <li>Caching primary rays and first intersections to eliminate redundant calculations.</li> </ul> </li> <li> <p><strong>Versatile Surface Shading</strong>: The path tracer supports a diverse range of surfaces, encompassing:</p> <ul> <li>Ideal diffusive (Lambertian) surfaces.</li> <li>Perfect and imperfect specular surfaces.</li> <li>Refractive materials.</li> </ul> </li> <li> <p><strong>Multiple Importance Sampling (MIS)</strong>: For shading imperfect specular surfaces, MIS is judiciously utilized to mitigate fireflies and reduce variance.</p> </li> <li> <p><strong>Advanced Antialiasing</strong>: Stochastic sampling with sub-pixel space jittering enhances antialiasing, ensuring smooth and polished edge renderings.</p> </li> <li> <p><strong>Authentic Depth-of-Field</strong>: The path tracer offers a physically-based depth-of-field, allowing for user-specified aperture diameters and focal lengths, enhanced with random aperture jittering.</p> </li> <li> <p><strong>Specialized Camera Effects</strong>:</p> <ul> <li> <strong>Fish-Eye Camera</strong>: Create wide-angle, distorted visual effects characteristic of a fish-eye lens.</li> <li> <strong>Panorama Camera</strong>: Capture sweeping, wide-angle views perfect for panoramic visuals.</li> </ul> </li> <li> <p><strong>Dynamic Motion Blur</strong>: Introducing motion into static scenes, the <code class="language-plaintext highlighter-rouge">VELOC</code> tag lets users assign velocity vectors to objects. Combined with adjustable shutter time, this feature vividly captures the effects of motion blur.</p> </li> </ul> <hr> <h2 id="path-tracing-pipeline">Path Tracing Pipeline</h2> <p>Our path tracer meticulously constructs a detailed rendering of a scene by iterating over rays projected from the camera, accumulating the final colors of each ray. The iterative process can be delineated into the following phases:</p> <ol> <li> <p><strong>Primary Ray Generation</strong>:</p> <ul> <li>In this phase, rays emanating from the camera are synthesized in a parallelized manner.</li> <li>A caching system is in place that, when activated, preserves primary rays and their initial intersections for reuse in subsequent iterations.</li> <li>In scenarios where caching is disabled, advanced features such as antialiasing, motion blur, and other intricate camera effects are operational.</li> </ul> </li> <li> <p><strong>Intersection Computation</strong>:</p> <ul> <li>A parallelized computation is carried out to determine each ray’s intersection against the entirety of the scene.</li> <li>The system is equipped to handle some of primitives, like cubes and spheres.</li> </ul> </li> <li> <p><strong>Shading &amp; Ray Scattering</strong>:</p> <ul> <li>Drawing from each ray’s properties and its intersection data, the ray’s color is refined using a selection of BSDFs. Furthermore, a direction is charted for the succeeding ray in the next iteration.</li> </ul> </li> <li> <p><strong>Partial Color Accumulation</strong>:</p> <ul> <li>Rays that either intersect with a light source or reach their bounce threshold have their colors aggregated.</li> <li>Stream compaction is utilized to remove these rays post color collection.</li> </ul> </li> <li> <p><strong>Termination Assessment</strong>:</p> <ul> <li>The iteration is concluded if no active rays remain. If active rays persist, the process returns to the second phase.</li> </ul> </li> </ol> <hr> <h1 id="features">Features</h1> <hr> <h2 id="1-bsdfs-for-basic-materials">1. BSDFs for Basic Materials</h2> <p>The path tracer has support for basic BSDFs, including pure diffusive (Lambertian) surfaces, and pure specular (mirror-like) surfaces.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/pure_diffusive-480.webp 480w,/assets/img/projects/cuda-pathtracer/pure_diffusive-800.webp 800w,/assets/img/projects/cuda-pathtracer/pure_diffusive-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/pure_diffusive.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/pure_specular-480.webp 480w,/assets/img/projects/cuda-pathtracer/pure_specular-800.webp 800w,/assets/img/projects/cuda-pathtracer/pure_specular-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/pure_specular.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Pure Diffusive (5000 iters, 8 depth). Right: Pure Specular (5000 iters, 8 depth). </div> <hr> <h2 id="2-active-path-stream-compaction">2. Active Path Stream Compaction</h2> <p>To minimize wrap divergence, terminated paths are removed at each bounce. This is done by first collect colors of terminated paths and then stream compaction which checks the remaining number of bounces for each ray. Stream compaction is implemented by <code class="language-plaintext highlighter-rouge">thrust::remove_if</code> function.</p> <p>To quantify the benefits of stream compaction, the number of active paths are recorded in every bounce, within one iteration. The original cornell box (open) and a closed cornell box are used to compare the benefits between open systems and close systems.</p> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/stream_compaction.svg" style="width: 100%; height: auto;"> <p>Stream Compaction Results</p> </div> <p>The graphs shows that for both open and closed boxes, the number of remaining active paths decrease as the number of bounces increases, but the decrease is more obvious in the open box. This is expected as open box allows paths to escape the box to enter the void, but not for closed boxes. Open box also has a steady decrease of active paths, which is due to paths hitting light sources and terminating prematurely. Therefore we can say that for this specific path tracer, the benefits of stream compaction increases for more closed system and also fore systems with more light sources.</p> <p>Compared to no stream compaction - launching 640,000 thread for 8 time, - stream compaction eliminates over 51.5% of number of threads launched in an open box, and only about 3.8% in a closed box. These threads correspond to inactive paths, and would cause an unnecessary overhead.</p> <hr> <h2 id="3-material-sorting">3. Material Sorting</h2> <p>Also to minimize wrap divergence, paths and their intersections are sorted acccording to the material type they hit in each iteration, so that each wrap will contain more threads that will access the same material info. <code class="language-plaintext highlighter-rouge">thust::sequence</code> is used to generate a sequence of indices, and then sorted with <code class="language-plaintext highlighter-rouge">thrust::sort</code> according to intersection material ids. Finally, paths and intersections are shuffled according to the sorted indices.</p> <p>To understand the outcome of this optimization, we measure average time to generate a frame, using the original Cornell box with only 4 material types.</p> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/material_sorting.svg" style="width: 100%; height: auto;"> <p>Material Sorting</p> </div> <p>Without material sorting, it takes about 3.0ms per frame. And with sorting, the time comes to 7.7ms. It is obvious that for this specific scene, sorting materials actually has negative impact on performance. Even though sorting materials indeed enhance memory coarsening, the sorting overhead dwarfs the benefit of memory coarsening, especially when the number of materials is low.</p> <hr> <h2 id="4-primary-ray--first-interaction-caching">4. Primary Ray &amp; First Interaction Caching</h2> <p>In situations where there is no randomization in the generation of first ray and the objects are static, primary rays are always the same, as well as their first intersections with the scene. Therefore, we can cache the primary rays at the beginning of the first iteration, in the <code class="language-plaintext highlighter-rouge">pathtraceInit()</code> method. When the camera moves, the init function will be called again, and the cache will be updated.</p> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/caching.svg" style="width: 100%; height: auto;"> <p>Primary Ray Caching</p> </div> <p>From the testing result under different maximum bounce limit, it seems that the performance difference is a constant factor, and does not increase with the bounce limit. This is expected because the only computation eliminated is the first bounce of each iteration, and subsequent bounces are the same. On my GPU, the performance gain of caching is on average 0.28ms.</p> <hr> <h2 id="5-refraction">5. Refraction</h2> <p>The path tracer also supports ideal refraction, combined with Frensel’s effect, which is emulated by Schlick’s approximation.</p> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/refraction.png" style="width: 100%; height: auto;"> <p>Refraction</p> </div> <p>This implementation only accounts for ideal reflections and refraction, so images refracted within spheres are sharp and not blurred.</p> <hr> <h2 id="6-imperfect-specular-surfaces-with-mis">6. Imperfect Specular Surfaces with MIS</h2> <p>To achieve a good mixture of diffusion and specular shading, MIS weights are used to lower the variance and promote convergence. To account for imperfect specular shading, rays leaving the surface are sampled in a lobe centering around the ideal reflect direction. The results resembles a good Phong shading result.</p> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/imperfect_specular.png" style="width: 100%; height: auto;"> <p>Imperfect Specular Reflection</p> </div> <p>The use of MIS weights, which are computed by PDFs for both sampling techniques, lowers the variance and appearance of fireflies drastically. On the contrary, if a 50/50 chance of refraction/reflection chance is chosen, the variance will be so high that the final image will be full of fireflies.</p> <hr> <h2 id="7-stochastic-antialiasing">7. Stochastic Antialiasing</h2> <p>To achieve smoother edges, antialiasing is accomplished by jittering primary rays within the range of a single pixel. Since randomization is introduced, primary ray caching is no longer feasible.</p> <p>Here is a side-by-side comparison of edges:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/w_antialiasing-480.webp 480w,/assets/img/projects/cuda-pathtracer/w_antialiasing-800.webp 800w,/assets/img/projects/cuda-pathtracer/w_antialiasing-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/w_antialiasing.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="With Antialiasing" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/wo_antialiasing-480.webp 480w,/assets/img/projects/cuda-pathtracer/wo_antialiasing-800.webp 800w,/assets/img/projects/cuda-pathtracer/wo_antialiasing-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/wo_antialiasing.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Without Antialiasing" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: With Antialiasing (5000 iters, 8 depth). Right: Without Antialiasing (5000 iters, 8 depth). </div> <hr> <h2 id="8-motion-blur">8. Motion Blur</h2> <p>In the scene file, a <code class="language-plaintext highlighter-rouge">VELOC</code> <code class="language-plaintext highlighter-rouge">vec3</code> tag can be added to each object to specify the velocity vector of its movement.</p> <p>To achieve a sense of movement, a time is randomly chosen from 0 to a specified shutter time, and objects will be updated to their respective position at that specific time, achieving a sampling at that time.</p> <p>To further show the acceleration of the object, time is sampled more often at the end of the shutter time, so the object is more solid at the end position of its movement.</p> <div align="center"> <img src="/assets/img/projects/cuda-pathtracer/motion_blue.png" style="width: 100%; height: auto;"> <p>Motion Blur</p> </div> <p>The sphere is specified a velocity of <code class="language-plaintext highlighter-rouge">[4, 0, 0]</code>, therefore moving to the right. It is obvious that the sphere is more solid on the right, which is the endpoint of its movement.</p> <hr> <h2 id="9-physically-based-depth-of-field">9. Physically-Based Depth-of-Field</h2> <p>Rather than using a traditional pin-hole camera, the origin of primary rays are instead generated within a small aperture space. The aperture diameter as well as the focal distance can then be specified.</p> <p>Focal distance is used to control the focal point and which objects should be sharp and clear:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/focal_left-480.webp 480w,/assets/img/projects/cuda-pathtracer/focal_left-800.webp 800w,/assets/img/projects/cuda-pathtracer/focal_left-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/focal_left.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Focal Length 12.38" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/focal_right-480.webp 480w,/assets/img/projects/cuda-pathtracer/focal_right-800.webp 800w,/assets/img/projects/cuda-pathtracer/focal_right-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/focal_right.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Focal Length 8.08" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Focal Length 12.38. Right: Focal Length 8.08. </div> <p>Aperture diameter is used to control the blur degree. Larger aperture means more blur at the same distance from the focal plain:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/aperture_1-480.webp 480w,/assets/img/projects/cuda-pathtracer/aperture_1-800.webp 800w,/assets/img/projects/cuda-pathtracer/aperture_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/aperture_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Aperture Diameter 1.0" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/aperture_5-480.webp 480w,/assets/img/projects/cuda-pathtracer/aperture_5-800.webp 800w,/assets/img/projects/cuda-pathtracer/aperture_5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/aperture_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Aperture Diameter 5.0" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Aperture Diameter 1.0. Right: Aperture Diameter 5.0. </div> <hr> <h2 id="10-alternative-camera-types">10. Alternative Camera Types</h2> <p>Fish-eye camera and Panorama camera are also available for this path tracer, by blending primary rays in a spherical or cylindrical coordination.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/fisheye-480.webp 480w,/assets/img/projects/cuda-pathtracer/fisheye-800.webp 800w,/assets/img/projects/cuda-pathtracer/fisheye-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/fisheye.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Fish Eye Camera" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/cuda-pathtracer/panorama-480.webp 480w,/assets/img/projects/cuda-pathtracer/panorama-800.webp 800w,/assets/img/projects/cuda-pathtracer/panorama-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/cuda-pathtracer/panorama.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Panorama Camera" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Fish Eye Camera. Right: Panorama Camera. </div> <hr> <h1 id="reference">Reference</h1> <ol> <li><a href="https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling" rel="external nofollow noopener" target="_blank">GPU Gems 3: Importance-based Sampling</a></li> </ol> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Yuanqi Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 27, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>